import pandas
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import OneHotEncoder
from sklearn.tree import export_graphviz
from six import StringIO
from IPython.display import Image  
import pydotplus
from pydotplus import graph_from_dot_data
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt
from sklearn.svm import LinearSVC, SVC
from sklearn.metrics import precision_score, make_scorer

import os
os.environ["PATH"] += os.pathsep + r'C:\Program Files\Graphviz\bin'

data = pandas.read_csv("ukol_04_data.csv")
#print(data.head())

import numpy

#část 1

y = data["y"]

categorical_columns = ["job", "marital", "education", "default", "housing", "loan", "contact", "campaign", "poutcome"]
numeric_columns = ["age", "balance", "duration", "pdays", "previous"]
numeric_data = data[numeric_columns].to_numpy()

encoder = OneHotEncoder()
encoded_columns = encoder.fit_transform(data[categorical_columns])
encoded_columns = encoded_columns.toarray()

X = numpy.concatenate([encoded_columns, numeric_data], axis=1)

print(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

clf = DecisionTreeClassifier(random_state=42, max_depth=4)
clf = clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

dot_data = StringIO()
export_graphviz(clf, out_file=dot_data, filled=True, feature_names=list(encoder.get_feature_names_out()) + numeric_columns, class_names=["no", "yes"])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
graph.write_png('tree.png')

ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test)
plt.show()



# matice záměn: př.: True + predicted label: 
# př. No + No -> 12917 - udává, že model a zároveň i realné hodnoty ve 12917 případech značí, že klienti nemají termínovaný účet
# př. No + Yes -> 292 - model nesprávně uvedl, že ve 292 případech klient má term.účet, i když reálně ho nemá (True label = no)

#metriky:
print(accuracy_score(y_test, y_pred))
print(precision_score(y_test, y_pred, pos_label="yes"))
print(recall_score(y_test, y_pred, pos_label="yes"))

#Vedení marketingového oddělení se chce vyhnout zbytečnému kontaktování klientů, kteří o termínovaný účet nemají zájem. 
#Nevadí, pokud se neozvou někomu, kdo o termínovaný vklad zájem má. Vyber podle této preference vedení vhodnou metriku.
# -> Vhodná metrika je precision score - Čím více klientů bez zájmu o term.účet označíme, že mají zájem, tím má metrika menší hodnotu. 
# Metrika nepočítá s tím, kolik klientů se zájmem o účet jsme označili za klienty, kteří zájem nemají.


#0.9018096514745308 = accuracy score -> tj. je cca 90 % - model je velmi přesný (90% správně určených záznamů)
# 0.6481927710843374 = precision score -> tj. cca 65 %  
# recall = 0.31443600233781416 (nezajímá nás v tomto případě)


# část 2 a 3

scaler = StandardScaler()
numeric_data = scaler.fit_transform(data[numeric_columns])

encoder = OneHotEncoder()
encoded_columns = encoder.fit_transform(data[categorical_columns])
encoded_columns = encoded_columns.toarray()

X = numpy.concatenate([encoded_columns, numeric_data], axis=1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


model_1 = KNeighborsClassifier()
params_1 = {"n_neighbors": (1, 32, 2)}
precision_scorer = make_scorer(precision_score, pos_label="yes")
clf_1 = GridSearchCV(model_1, params_1, scoring=precision_scorer)

clf_1.fit(X, y)
y_pred = clf_1.predict(X_test)

print(clf_1.best_params_)
print(round(clf_1.best_score_, 2))
print(precision_score(y_test, y_pred, pos_label="yes"))


# nejlepším výsledkem je 'n_neighbors': 19 a precision 0.56

model_2 = SVC(kernel="linear")
params_2 = {"decision_function_shape": ["ovo", "ovr"]}

clf_2 = GridSearchCV(model_2, params_2, scoring="accuracy")
clf_2.fit(X, y)
y_pred = clf_2.predict(X_test)
print(clf_2.best_params_)
print(round(clf_2.best_score_, 2))

print(precision_score(y_test, y_pred, pos_label="yes"))


scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

clf_2 = LinearSVC()
clf_2.fit(X_train, y_train)
y_pred = clf_2.predict(X_test)
print(precision_score(y_test, y_pred, pos_label="yes"))

# výsledek 0.66


# nepjpřesněji mi nevychází metoda rozhodovacího stromu s hloubkou 4 ( precision score je cca 65 %) ale metoda LinearSVC s 66% hodnotou metriky precision



# bonus - např. pro hloubku rozh.stromu = 5 vychází accuracy = 0.9004691689008043
# bonus - pro hloubku = 10 je accuracy = 0.8979222520107238
